---
title: 'Data Management & Analysis Final Project'
subtitle: 'Replication and Extention for Acemoglu, Naidu, Restrepo and Robinson (2019)'
author: 
  - "(Name:) Shoya Abe (University ID:) 31B24001"
  - "(Name:) Honoka Otani (University ID:) 31B24002"
date: "(Submission Due:) 2025/02/06"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
  html_document:
    df_print: paged
    toc: true
    toc_depth: 3
    number_sections: true
  word_document:
    toc: true
    toc_depth: 3
    number_sections: true
bibliography: references.bib
nocite: '@*'
header-includes:
  - \usepackage{booktabs}
  - \usepackage{float}
  - \usepackage[table]{xcolor}
geometry: margin=1in
---

\newpage

## Setup
  
```{r setup, echo=TRUE, cache=FALSE, warning=FALSE, message=FALSE}
pacman::p_load(
  rmdformats,
  knitr,
  tinytex,
  haven,
  tidyverse,
  kableExtra,
  plm,
  texreg
)
options(max.print = "75")
opts_chunk$set(
  fig.align = "center",
  echo = TRUE,
  cache = TRUE,
  prompt = FALSE,
  tidy = FALSE,
  comment = NA,
  message = FALSE,
  warning = FALSE
)
opts_knit$set(width = 75)
```

# About this Report

## Project Type

In this report, we replicate and extend the previous paper. The paper we replicate is Acemoglu, D., Naidu, S., Restrepo, P., & Robinson, J. A. (2019). “Democracy Does Cause Growth.” \textit{Journal of Political Economy}, 127(1), 47–100. \url{https://doi.org/10.1086/700936}.

We try to replicate Figure.1, Table.1, Table.2 and Table.6 in the paper, which are especially critical results in the paper. We also try several extension approaches using the bootstrap method. In appendix, we replicate Arellano Bond Estimation for Table.2 because we failed to replicate due to several limitations.

## Summary of the Paper (Honoka Otani)

### What the problem is

The authors attempted to provide a clear answer to the widely divergent topic of opinion on the causal relationship between democracy and economic growth. At the time of writing, there was a widely shared view that democracy has no relation to, or rather a negative effect on, economic growth. 

On the other hand, there were empirical studies that showed a positive effect of democracy on economic growth, but they did not adequately address the endogeneity issue between political regimes and economic growth. 

This paper points to four main challenges in estimating the causal relationship between democracy and economic growth. First, existing democracy indicators are subject to measurement error and changes in scores may not accurately reflect actual changes in political regimes. Second, there are institutional, historical and cultural differences between democracies and nondemocracies that also affect economic growth, which may introduce bias in the analysis. Third, democratization tends to occur after a temporary drop in GDP, which can bias estimates if not captured correctly in the model. Fourth, democratization and economic growth may be affected by common external factors, making it difficult to identify causality.


### Why it is important

Demonstrating the causal relationship between democracy and economic growth has important implications for both political and economic development strategies. If democracy has a positive effect on economic growth, it provides an incentive to promote democratization across the world. It would also provide important hints to each country seeking to achieve economic growth. By providing empirical evidence, this study contributes to the competing debate on governance and economic growth.

### How you solve the problem

To address the problem of measurement error in democracy indicators, the authors introduced a new democracy indicator by integrating several existing measurement methods.

For other endogeneity problems, the authors employed three empirical strategies.

First, a dynamic (linear) panel model is used to control for country fixed effects and autoregressive GDP dynamics. By including lags of GDP per capita, this model accounts for the pre-democratization dip in GDP, ensuring that countries transitioning to democracy are not on a different GDP trend compared to other countries with similar past GDP levels.

Second, they adopted a propensity score reweighting strategy semiparametric treatment effects framework which democratization influences the distribution of potential GDP in all subsequent years. This method models the selection into democracy as a function of observable factors, particularly past GDP, without relying on a fully parametric GDP model. This approach increases flexibility in estimating how democracy influences GDP over time.

Third, they applied an instrumental variables (IV) method, using regional waves of democratization as an instrument for a country's transition to democracy. Since democratizations often occur in regional clusters, this method isolates exogenous variation in democracy that is not directly related to a country's own economic conditions. By leveraging this external source of variation, the IV approach strengthens the identification of the causal effect of democracy on GDP.

As for extension part, in order to visualize the uncertainty of the long-term impact of democratization on economic growth, we estimate the confidence interval of the ATT estimate using the bootstrap method based on the event study in Figure 1.

### What we find

The findings of this paper demonstrate that democracy has a significant positive effect on GDP per capita. A country that transitions from nondemocracy to democracy experiences a long-run increase in GDP per capita of approximately 20–25% over the next 25 years. This effect is robust across different three strategies.  

Furthermore, the analysis shows that the effect does not depend on a country’s initial level of development, however, the effect is stronger in countries with higher levels of secondary education.  

The authors also suggest several channels through which democracy promotes economic growth. They showed that democracy increases economic reforms, tax revenue (as a percentage of GDP). And enrollment in primary and secondary education and reduces child mortality rate. They also found the possibility that democracy promotes investment and open trade, and reduces social unrest.

Overall, the findings of this study strongly support the claim that democracy causes economic growth. This effect is primarily driven by democracy’s ability to increase investment, improve human capital through education and healthcare, and strengthen governance structures, while also contributing to greater political stability and reduced social unrest. These results challenge the notion that democracy is a hindrance to economic growth and instead emphasize its role in fostering sustainable and inclusive economic growth.

As for extension part, we found that the long-term impact of democratization on economic growth is quite uncertain.

## Data (Shoya Abe)

We use data obtained from the replication files available in the data archive on Professor Daron Acemoglu's homepage. This dataset consists of a large panel of 175 countries from 1960 to 2010. The sample size is 9,384, and the number of variables is 1,177. A list of variables is provided in the appendix.

```{r}
data <- read_dta("data/raw/DDCGdata_final.dta")

summarize_data <- function(data, n = 10) {
  cat("Sample size (number of rows):", nrow(data), "\n")
  cat("Number of variables (columns):", ncol(data), "\n")
}

summarize_data(data)
```

## Empirical Methods (Shoya Abe)

We briefly explain the empirical methods we use for our replication. The original paper used a number of empirical methods to strengthen the robustness of the results. Among them, we replicate three main strategy below\footnote{We also worked on Arellano Bond estimation in table.2. However, it took an enormous amount of computation time and the results obtained were quite different from the original results. In other words, replication failed. However, in the belief that it is desirable to disclose the entire analysis process and results, we disclose the analysis code and results in the appendix.}.

### Event Study (Figure.1)

First, we conduct the event study. We estimate the average treatment effect (ATT) for the treated group using the procedure described below.

First, let \( T_c \) denote the year in which a given country experienced the democratization event. For any country \( c \) and year \( t \), we define the relative year as
\begin{align}
\tau_{c,t} = t - T_c.
\end{align}
Then, taking the outcome \( y \) in the year immediately preceding democratization (i.e., when \( \tau = -1 \)) as the baseline, the outcome of interest is defined as
\begin{align}
\text{gdpDiff}_{c,t} = y_{c,t} - y_{c,T_c-1}.
\end{align}

Next, we estimate the following regression model using the control group that did not experience democratization:
\begin{align}
\text{gdpDiff}_{c,t} = \sum_{\tau=-15,\ \tau\neq -1}^{30} \beta_{\tau} \, \mathbf{1}\{\tau_{c,t} = \tau\} + \epsilon_{c,t}.
\end{align}

The estimated coefficient \( \hat{\beta}_{\tau_{c,t}} \) from (3) can be interpreted as the counterfactual outcome for country \( c \) in year \( t \) in the absence of democratization. Therefore, the average difference between the observed outcome and this counterfactual outcome provides an estimate of the ATT for relative year \( \tau \), which is calculated as
\begin{align}
\text{ATT}(\tau) = \frac{1}{N_{\tau}^{\text{treated}}} \sum_{\substack{(c,t) \in \text{treated} \\ \tau_{c,t} = \tau}} \Bigl( \text{gdpDiff}_{c,t} - \hat{\beta}_{\tau} \Bigr).
\end{align}


### Dynamic Liner Panel Model (Table.2)

Next, we estimate the following dynamic linear panel model.
\begin{align}
&y_{c,t} = \beta D_{c,t} + \gamma_1 y_{c,t-1} + \alpha_c + \delta_t + \epsilon_{ct}, \\
&y_{c,t} = \beta D_{c,t} + \sum_{j = 1}^2 \gamma_j y_{c,t-j} + \alpha_c + \delta_t + \epsilon_{c,t},  \\
&y_{c,t} = \beta D_{c.t} + \sum_{j = 1}^4 \gamma_j y_{c,t-j} + \alpha_c + \delta_t + \epsilon_{c,t},  \\
&y_{c,t} = \beta D_{c,t} + \sum_{j = 1}^8 \gamma_j y_{,ct-j} + \alpha_c + \delta_t + \epsilon_{c,t}, 
\end{align}
where $y_{ct}$ is the log of GDP per capita in country $c$ at time $t$ and $D_{ct}$ is a dummy variable that takes the value 1 if country $c$ is a democracy at time $t$ and 0 otherwise.

### Inverse-Propensity-Score Reweighting (Figure.4)

First, we estimate the following probit regression model and derive the propensity score \( p(X) \) for the transition to democratization.
\begin{align}
Pr(transition = 1 | X) = \Phi \left( \gamma_0 + \sum_{j=1}^4 \gamma_j y_{c,t-j} + \sum_{\tau} \beta_{\tau} \mathbf{1} \{ \tau_{c,t} = \tau \}  \right).
\end{align}
Next, based on the estimated propensity score \( \hat{p}(X_i) \), we define the weight \( w_c \) for each observation as follows.
\begin{equation}
w_c =
\left\{ \,
    \begin{aligned}
    1, \quad \quad \quad &\text{if} \, transition_c = 1,\\
    \frac{\hat{P}(X_c)}{1 - \hat{P}(X_c)},  \quad &\text{if} 
    \, transition_c = 0.
    \end{aligned}
\right.
\end{equation}
Using this weight, we can estimate ATT as follows\footnote{This method is also known as Inverse Probability Weighting (IPW) estimation and is a representative approach in semiparametric estimation.}.
\begin{align}
\hat{\text{ATT}} = \frac{1}{N_1} \sum_{c:transition_c = 1} Y_i - \frac{\sum_{c:transition_c = 0}w_c Y_c}{\sum_{c:transition_c = 0}w_c},
\end{align}
where $N_1$ is the sample size on treatment group. For the standard errors, we use the bootstrap method for estimation. This approach will be explained in the extension part.

### Instrumental Variable (IV) Method (Table.6)

Finally, we adopt the instrumental variable (IV) method. The instrumental variables used in this analysis are as follows.
\begin{align}
Z_{ct} = \frac{1}{|I_c|} \sum_{{c^*} \in I_c} D_{ {c^*} t}. 
\end{align}
Using this instrumental variable, we conduct the following 2SLS estimation.
\begin{align}
& y_{ct} = \beta D_{ct} + \sum_{j=1}^p \gamma y_{ct-j} + \alpha_c + \delta_t + \epsilon_{ct}, \\
& D_{ct} = \sum_{j=1}^q \pi_j Z_{ct-j} + \sum_{j=1}^p \phi_j y_{ct-j} + \theta_c + \mu_t + v_{ct}
\end{align}

# Replication

## Figure.1 (Shoya Abe)

### Preprocessing

```{r}
data_f1 <- data |>
  rename(id = "_ID") |>
  group_by(id) |>
  arrange(year) |>
  mutate(
    prev_dem = dplyr::lag(dem, 1),
    transition = case_when(
      dem == 1 & prev_dem == 0 ~ 1,
      dem == 0 & prev_dem == 0 ~ 0,
      TRUE ~ NA_real_
    ),
    lag1 = dplyr::lag(y, 1),
    lag2 = dplyr::lag(y, 2),
    lag3 = dplyr::lag(y, 3),
    lag4 = dplyr::lag(y, 4)
  ) |>
  filter(
    !is.na(lag1) & !is.na(lag2) &
      !is.na(lag3) & !is.na(lag4)
  ) |>
  ungroup()

for (t in -15:-2) {
  col_name <- paste0("gdpDiff_m", abs(t))
  data_f1 <- data_f1 |>
    group_by(id) |>
    arrange(year) |>
    mutate(!!col_name := dplyr::lag(y, abs(t)) - lag1) |>
    ungroup()
}

data_f1 <- data_f1 |>
  mutate(
    gdpDiff_m1 = 0,
    gdpDiff_0 = y - lag1
  )

for (t in 1:30) {
  col_name <- paste0("gdpDiff_p", t)
  data_f1 <- data_f1 |>
    group_by(id) |>
    arrange(year) |>
    mutate(!!col_name := dplyr::lead(y, t) - lag1) |>
    ungroup()
}

data_f1 <- data_f1 |>
  filter(!is.na(transition))
```

### Estimation

```{r}
estimateATT <- function(outcome_col) {
  sub_data <- data_f1 |>
    filter(!is.na(.data[[outcome_col]]), !is.na(transition))
  if (nrow(sub_data) == 0) return(NA)
  year_levels <- sort(unique(sub_data$year))
  sub_data <- sub_data |>
    mutate(year_factor = factor(year, levels = year_levels))
  control_data <- sub_data |>
    filter(transition == 0)
  treated_data <- sub_data |>
    filter(transition == 1)
  if (nrow(control_data) < 2 ||
      length(unique(control_data$year)) < 2) return(NA)
  model_formula <- as.formula(
    paste(outcome_col, "~ year_factor - 1")
  )
  control_model <- tryCatch(
    lm(model_formula, data = control_data),
    error = function(e) NULL
  )
  if (is.null(control_model)) return(NA)
  predicted_outcomes <- tryCatch(
    predict(control_model, newdata = treated_data),
    error = function(e) rep(NA, nrow(treated_data))
  )
  treatment_effects <- treated_data[[outcome_col]] - predicted_outcomes
  mean(treatment_effects, na.rm = TRUE)
}

relative_times <- c(seq(-15, -1), seq(0, 30))
atets <- numeric(length(relative_times))

for (i in seq_along(relative_times)) {
  t_val <- relative_times[i]
  if (t_val < 0) {
    col_name <- paste0("gdpDiff_m", abs(t_val))
  } else {
    col_name <- if (t_val == 0) {
      "gdpDiff_0"
    } else {
      paste0("gdpDiff_p", t_val)
    }
  }
  atets[i] <- estimateATT(col_name)
}

results_df <- data.frame(
  RelativeTime = relative_times,
  ATT = atets
)
```

### Plot

```{r}
figure_1 <- ggplot(results_df, aes(x = RelativeTime, y = ATT)) +
  geom_line(color = "black") +
  scale_x_continuous(breaks = seq(-15, 30, 5)) +
  labs(
    x = "Years around Democratization",
    y = "Change in GDP per capita (log points)"
  ) +
  theme_bw()

ggsave(
  "output/figure_1.pdf",
  width = 14,
  height = 8,
  units = "cm"
)
```

![The Long-Term Impact of Democratization on Economic Growth](output/figure_1.pdf)

## Table.1 (Honoka Otani)

### Preprocessing

```{r}
var_info <- tibble(
  var = c(
    "gdppercapitaconstant2000us",
    "loginvpc",
    "ltrade2",
    "lp_bl",
    "ls_bl",
    "lgov",
    "mortnew",
    "unrestn",
    "marketref"
  ),
  label = c(
    "GDP per capita",
    "Investment share of GDP",
    "Trade share of GDP",
    "Primary-school enrollment rate",
    "Secondary-school enrollment rate",
    "Tax revenue share of GDP",
    "Child mortality per 1,000 births",
    "Unrest rate",
    "Market reforms index (0–100)"
  )
)

data_sub <- data |>
  select(dem, all_of(var_info$var))
```

### Caliculation

```{r}
calc_stats <- function(variable) {
  non_demo <- data_sub |>
    filter(dem == 0) |>
    pull(.data[[variable]])
  non_demo <- non_demo[!is.na(non_demo)]
  demo <- data_sub |>
    filter(dem == 1) |>
    pull(.data[[variable]])
  demo <- demo[!is.na(demo)]
  tibble(
    var = variable,
    n_non_demo = length(non_demo),
    mean_non_demo = mean(non_demo),
    sd_non_demo = sd(non_demo),
    n_demo = length(demo),
    mean_demo = mean(demo),
    sd_demo = sd(demo)
  )
}

summary_table <- map_dfr(var_info$var, calc_stats) |>
  left_join(var_info, by = "var") |>
  select(label, n_non_demo, mean_non_demo, sd_non_demo, n_demo, mean_demo, sd_demo)
```

### Tabulation

```{r}
latex_table <- summary_table |>
  kbl(
    caption = "Summary Statistics by Democracy Status",
    format = "latex",
    booktabs = TRUE,
    digits = 2,
    col.names = c("", "N", "Mean", "SD", "N", "Mean", "SD")
  ) |>
  add_header_above(c(" " = 1, "Nondemocracies" = 3, "Democracies" = 3)) |>
  kable_styling(latex_options = c("HOLD_position", "striped"))

save_kable(latex_table, file = "output/table_1.tex")
```

\input{output/table_1.tex}

## Table.2 (Honoka Otani)

### Preprocessing

```{r}
data_t2 <- data |>
  select(1:30) |>
  group_by(country_name) |>
  arrange(year) |>
  mutate(
    lag1 = dplyr::lag(y, 1),
    lag2 = dplyr::lag(y, 2),
    lag3 = dplyr::lag(y, 3),
    lag4 = dplyr::lag(y, 4),
    lag5 = dplyr::lag(y, 5),
    lag6 = dplyr::lag(y, 6),
    lag7 = dplyr::lag(y, 7),
    lag8 = dplyr::lag(y, 8)
  ) |>
  ungroup()
```

### Estimation

```{r}
data_m1 <- data_t2 |>
  drop_na(y, dem, lag1) |>
  pdata.frame(index = c("country_name", "year"))
model_1 <- plm(
  y ~ dem + lag1,
  data = data_m1,
  model = "within",
  effect = "twoways"
)

data_m2 <- data_t2 |>
  drop_na(y, dem, lag1, lag2) |>
  pdata.frame(index = c("country_name", "year"))
model_2 <- plm(
  y ~ dem + lag1 + lag2,
  data = data_m2,
  model = "within",
  effect = "twoways"
)

data_m3 <- data_t2 |>
  drop_na(y, dem, lag1, lag2, lag3, lag4) |>
  pdata.frame(index = c("country_name", "year"))
model_3 <- plm(
  y ~ dem + lag1 + lag2 + lag3 + lag4,
  data = data_m3,
  model = "within",
  effect = "twoways"
)

data_m4 <- data_t2 |>
  drop_na(
    y, dem, lag1, lag2, lag3, lag4,
    lag5, lag6, lag7, lag8
  ) |>
  pdata.frame(index = c("country_name", "year"))
model_4 <- plm(
  y ~ dem + lag1 + lag2 + lag3 + lag4 +
    lag5 + lag6 + lag7 + lag8,
  data = data_m4,
  model = "within",
  effect = "twoways"
)

beta_hat_1 <- coef(model_1)["dem"]
gamma_hat_1 <- coef(model_1)["lag1"]
long_run_effect_1 <- beta_hat_1 / (1 - sum(gamma_hat_1))

beta_hat_2 <- coef(model_2)["dem"]
gamma_hat_2 <- coef(model_2)[c("lag1", "lag2")]
long_run_effect_2 <- beta_hat_2 / (1 - sum(gamma_hat_2))

beta_hat_3 <- coef(model_3)["dem"]
gamma_hat_3 <- coef(model_3)[c("lag1", "lag2", "lag3", "lag4")]
long_run_effect_3 <- beta_hat_3 / (1 - sum(gamma_hat_3))

beta_hat_4 <- coef(model_4)["dem"]
gamma_hat_4 <- coef(model_4)[
  c("lag1", "lag2", "lag3", "lag4",
    "lag5", "lag6", "lag7", "lag8")
]
long_run_effect_4 <- beta_hat_4 / (1 - sum(gamma_hat_4))

lre <- round(
  c(long_run_effect_1, long_run_effect_2,
    long_run_effect_3, long_run_effect_4),
  3
)

pers1 <- sum(coef(model_1)[2])
pers2 <- sum(coef(model_2)[2:3])
pers3 <- sum(coef(model_3)[2:5])
pers4 <- sum(coef(model_4)[2:9])
pers <- round(c(pers1, pers2, pers3, pers4), 3)

dem_shortrun <- coef(model_1)["dem"]
lag1_mod1 <- coef(model_1)[2]
effect1 <- dem_shortrun
effect2 <- (effect1 * lag1_mod1) + dem_shortrun
effects_mod1 <- c(effect1, effect2)
for (i in 3:30) {
  eff <- (effects_mod1[i - 1] * lag1_mod1) + dem_shortrun
  effects_mod1 <- c(effects_mod1, eff)
}
eff_25_1 <- effects_mod1[25]

dem_shortrun <- coef(model_2)["dem"]
lag1_mod2 <- coef(model_2)[2]
lag2_mod2 <- coef(model_2)[3]
effect1 <- dem_shortrun
effect2 <- (effect1 * lag1_mod2) + dem_shortrun
effect3 <- (effect2 * lag1_mod2) +
  (effect1 * lag2_mod2) + dem_shortrun
effects_mod2 <- c(effect1, effect2, effect3)
for (i in 4:30) {
  eff <- (effects_mod2[i - 1] * lag1_mod2) +
    (effects_mod2[i - 2] * lag2_mod2) +
    dem_shortrun
  effects_mod2 <- c(effects_mod2, eff)
}
eff_25_2 <- effects_mod2[25]

dem_shortrun <- coef(model_3)["dem"]
lag1_mod3 <- coef(model_3)[2]
lag2_mod3 <- coef(model_3)[3]
lag3_mod3 <- coef(model_3)[4]
lag4_mod3 <- coef(model_3)[5]
effect1 <- dem_shortrun
effect2 <- (effect1 * lag1_mod3) + dem_shortrun
effect3 <- (effect2 * lag1_mod3) +
  (effect1 * lag2_mod3) + dem_shortrun
effect4 <- (effect3 * lag1_mod3) +
  (effect2 * lag2_mod3) +
  (effect1 * lag3_mod3) + dem_shortrun
effects_mod3 <- c(effect1, effect2, effect3, effect4)
for (i in 5:30) {
  eff <- (effects_mod3[i - 1] * lag1_mod3) +
    (effects_mod3[i - 2] * lag2_mod3) +
    (effects_mod3[i - 3] * lag3_mod3) +
    (effects_mod3[i - 4] * lag4_mod3) +
    dem_shortrun
  effects_mod3 <- c(effects_mod3, eff)
}
eff_25_3 <- effects_mod3[25]

dem_shortrun <- coef(model_4)["dem"]
lag1_mod4 <- coef(model_4)[2]
lag2_mod4 <- coef(model_4)[3]
lag3_mod4 <- coef(model_4)[4]
lag4_mod4 <- coef(model_4)[5]
lag5_mod4 <- coef(model_4)[6]
lag6_mod4 <- coef(model_4)[7]
lag7_mod4 <- coef(model_4)[8]
lag8_mod4 <- coef(model_4)[9]
effect1 <- dem_shortrun
effect2 <- (effect1 * lag1_mod4) + dem_shortrun
effect3 <- (effect2 * lag1_mod4) +
  (effect1 * lag2_mod4) + dem_shortrun
effect4 <- (effect3 * lag1_mod4) +
  (effect2 * lag2_mod4) +
  (effect1 * lag3_mod4) + dem_shortrun
effect5 <- (effect4 * lag1_mod4) +
  (effect3 * lag2_mod4) +
  (effect2 * lag3_mod4) +
  (effect1 * lag4_mod4) + dem_shortrun
effect6 <- (effect5 * lag1_mod4) +
  (effect4 * lag2_mod4) +
  (effect3 * lag3_mod4) +
  (effect2 * lag4_mod4) +
  (effect1 * lag5_mod4) + dem_shortrun
effect7 <- (effect6 * lag1_mod4) +
  (effect5 * lag2_mod4) +
  (effect4 * lag3_mod4) +
  (effect3 * lag4_mod4) +
  (effect2 * lag5_mod4) +
  (effect1 * lag6_mod4) + dem_shortrun
effect8 <- (effect7 * lag1_mod4) +
  (effect6 * lag2_mod4) +
  (effect5 * lag3_mod4) +
  (effect4 * lag4_mod4) +
  (effect3 * lag5_mod4) +
  (effect2 * lag6_mod4) +
  (effect1 * lag7_mod4) + dem_shortrun
effects_mod4 <- c(
  effect1, effect2, effect3, effect4,
  effect5, effect6, effect7, effect8
)
for (i in 9:30) {
  eff <- (effects_mod4[i - 1] * lag1_mod4) +
    (effects_mod4[i - 2] * lag2_mod4) +
    (effects_mod4[i - 3] * lag3_mod4) +
    (effects_mod4[i - 4] * lag4_mod4) +
    (effects_mod4[i - 5] * lag5_mod4) +
    (effects_mod4[i - 6] * lag6_mod4) +
    (effects_mod4[i - 7] * lag7_mod4) +
    (effects_mod4[i - 8] * lag8_mod4) +
    dem_shortrun
  effects_mod4 <- c(effects_mod4, eff)
}
eff_25_4 <- effects_mod4[25]

eff_25 <- round(
  c(eff_25_1, eff_25_2, eff_25_3, eff_25_4),
  3
)

se1 <- sqrt(diag(vcov(model_1)))
se2 <- sqrt(diag(vcov(model_2)))
se3 <- sqrt(diag(vcov(model_3)))
se4 <- sqrt(diag(vcov(model_4)))

override.coef.1 <- c(
  coef(model_1)["dem"],
  coef(model_1)["lag1"],
  NA, NA, NA, NA, NA, NA, NA
)
override.se.1 <- c(
  se1["dem"],
  se1["lag1"],
  NA, NA, NA, NA, NA, NA, NA
)

override.coef.2 <- c(
  coef(model_2)["dem"],
  coef(model_2)["lag1"],
  coef(model_2)["lag2"],
  NA, NA, NA, NA, NA, NA
)
override.se.2 <- c(
  se2["dem"],
  se2["lag1"],
  se2["lag2"],
  NA, NA, NA, NA, NA, NA
)

override.coef.3 <- c(
  coef(model_3)["dem"],
  coef(model_3)["lag1"],
  coef(model_3)["lag2"],
  coef(model_3)["lag3"],
  coef(model_3)["lag4"],
  NA, NA, NA, NA
)
override.se.3 <- c(
  se3["dem"],
  se3["lag1"],
  se3["lag2"],
  se3["lag3"],
  se3["lag4"],
  NA, NA, NA, NA
)

override.coef.4 <- c(
  coef(model_4)["dem"],
  coef(model_4)["lag1"],
  coef(model_4)["lag2"],
  coef(model_4)["lag3"],
  coef(model_4)["lag4"],
  coef(model_4)["lag5"],
  coef(model_4)["lag6"],
  coef(model_4)["lag7"],
  coef(model_4)["lag8"]
)
override.se.4 <- c(
  se4["dem"],
  se4["lag1"],
  se4["lag2"],
  se4["lag3"],
  se4["lag4"],
  se4["lag5"],
  se4["lag6"],
  se4["lag7"],
  se4["lag8"]
)
```

### Tabulation

```{r}
models <- list(model_1, model_2, model_3, model_4)
texreg(
  models,
  override.coef = list(
    override.coef.1,
    override.coef.2,
    override.coef.3,
    override.coef.4
  ),
  override.se = list(
    override.se.1,
    override.se.2,
    override.se.3,
    override.se.4
  ),
  custom.model.names = c("(1)", "(2)", "(3)", "(4)"),
  custom.coef.names = c(
    "Democracy", "Lag 1", "Lag 2",
    "Lag 3", "Lag 4", "Lag 5",
    "Lag 6", "Lag 7", "Lag 8"
  ),
  custom.gof.rows = list(
    "Persistence" = pers,
    "Long run effect" = lre,
    "Effect after 25 years" = eff_25
  ),
  file = "output/table_2_FE.tex",
  caption = "Effect of Democracy on (Log) GDP per Capita"
)
```

\input{output/table_2_FE.tex}

## Figure.4

### Preprocessing

```{r}
data_ipw <- read_dta("data/raw/impulse_ipw_alt.dta")

data_ipw <- data_ipw |> 
  separate(parm, 
           into = c("parm1", "parm2"), 
           sep = "c", 
           extra = "merge", 
           fill = "right")

data_ipw <- data_ipw |> 
  filter(parm2 != "") |> 
  mutate(parm2 = as.numeric(parm2))


data_ipw <- data_ipw |> 
  mutate(time = parm2 - 16)
```

### Plot

```{r}
figure_4 <- ggplot(data_ipw, aes(x = time, y = estimate)) +
  geom_line(color = "black") +
  geom_ribbon(aes(ymin = min95, ymax = max95), fill = "skyblue", alpha = 0.3) +
  labs(x = "Years around democratization",
       y = "Change in GDP per capita (log points)") +
  scale_x_continuous(breaks = seq(-15, 30, 5)) +
  theme_bw() 

ggsave("output/figure_4.pdf", 
       figure_4, 
       width = 14, 
       height = 8, 
       units = "cm")
```

![Semiparametric Estimation](output/figure_4.pdf)

## Table.5 

### Preprocessing

```{r, echo=TRUE, eval=FALSE}
data_f1 <- data |>
  rename(id = "_ID") |>
  group_by(id) |>
  arrange(year) |>
  ungroup()

data_f1 <- data_f1 |>
  group_by(id) |>
  arrange(year) |>
  mutate(prev_dem = dplyr::lag(dem, 1)) |>
  ungroup() |>
  mutate(transition = case_when(
    dem == 1 & prev_dem == 0 ~ 1,
    dem == 0 & prev_dem == 0 ~ 0,
    TRUE ~ NA_real_
  ))

data_f1 <- data_f1 |>
  group_by(id) |>
  arrange(year) |>
  mutate(
    lag1 = dplyr::lag(y, 1),
    lag2 = dplyr::lag(y, 2),
    lag3 = dplyr::lag(y, 3),
    lag4 = dplyr::lag(y, 4)
  ) |>
  ungroup() |>
  filter(!is.na(lag1) & !is.na(lag2) & !is.na(lag3) & !is.na(lag4))

for (t in -15:-2) {
  col_name <- paste0("gdpDiff_m", abs(t))
  data_f1 <- data_f1 |>
    group_by(id) |>
    arrange(year) |>
    mutate(!!col_name := dplyr::lag(y, abs(t)) - lag1) |>
    ungroup()
}

data_f1 <- data_f1 |>
  mutate(gdpDiff_m1 = 0)

data_f1 <- data_f1 |>
  group_by(id) |>
  arrange(year) |>
  mutate(gdpDiff_0 = y - lag1) |>
  ungroup()

for (t in 1:30) {
  col_name <- paste0("gdpDiff_p", t)
  data_f1 <- data_f1 |>
    group_by(id) |>
    arrange(year) |>
    mutate(!!col_name := dplyr::lead(y, t) - lag1) |>
    ungroup()
}

data_f1 <- data_f1 |> filter(!is.na(transition))
```


### Estimation

```{r, echo=TRUE, eval=FALSE}
compute_atet_ipw <- function(outcome_var, data) {
  df <- data |>
    filter(!is.na(!!sym(outcome_var)),
           !is.na(transition),
           !is.na(lag1), !is.na(lag2), !is.na(lag3), !is.na(lag4),
           !is.na(year))
  prop_model <- glm(transition ~ lag1 + lag2 + lag3 + lag4 + factor(year),
                    data = df, family = binomial(link = "probit"))
  df <- df |> mutate(ps = predict(prop_model, type = "response"))
  df <- df |> mutate(weight = ifelse(transition == 0, ps/(1 - ps), 1))
  treated_outcome <- df |> filter(transition == 1) |> pull(!!sym(outcome_var))
  control_df <- df |> filter(transition == 0)
  control_outcome <- control_df[[outcome_var]]
  control_weight  <- control_df$weight
  att <- mean(treated_outcome) - (sum(control_outcome * control_weight) / sum(control_weight))
  return(att)
}

compute_att_ipw_boot <- function(outcome_var, data, B = 200) {
  att_est <- compute_atet_ipw(outcome_var, data)
  n <- nrow(data)
  boot_est <- numeric(B)
  set.seed(123)
  for (b in 1:B) {
    boot_indices <- sample(1:n, size = n, replace = TRUE)
    boot_data <- data[boot_indices, ]
    boot_est[b] <- compute_atet_ipw(outcome_var, boot_data)
  }
  se_est <- sd(boot_est)
  return(list(att = att_est, se = se_est, boot = boot_est))
}

outcome_vars <- c(
  paste0("gdpDiff_m", 15:2),
  "gdpDiff_m1",
  "gdpDiff_0",
  paste0("gdpDiff_p", 1:30)
)

att_results <- list()
for (var in outcome_vars) {
  att_results[[var]] <- compute_att_ipw_boot(var, data_f1, B = 200)
}

group_definitions <- list(
  "-5 to -1" = c("gdpDiff_m5", "gdpDiff_m4", "gdpDiff_m3", "gdpDiff_m2", "gdpDiff_m1"),
  "0 to 4"   = c("gdpDiff_0", "gdpDiff_p1", "gdpDiff_p2", "gdpDiff_p3", "gdpDiff_p4"),
  "5 to 9"   = paste0("gdpDiff_p", 5:9),
  "10 to 14" = paste0("gdpDiff_p", 10:14),
  "15 to 19" = paste0("gdpDiff_p", 15:19),
  "20 to 24" = paste0("gdpDiff_p", 20:24),
  "26 to 30" = paste0("gdpDiff_p", 26:30)
)

group_results <- list()
for (grp in names(group_definitions)) {
  vars_in_grp <- group_definitions[[grp]]
  att_vec <- sapply(vars_in_grp, function(x) att_results[[x]]$att)
  boot_mat <- sapply(vars_in_grp, function(x) att_results[[x]]$boot)
  grp_boot <- rowMeans(boot_mat)
  grp_att <- mean(att_vec)
  grp_se <- sd(grp_boot)
  group_results[[grp]] <- list(att = grp_att, se = grp_se)
}

group_names <- names(group_results)
table_values <- sapply(group_names, function(grp) {
  sprintf("%.3f", group_results[[grp]]$att)
})
table_ses <- sapply(group_names, function(grp) {
  sprintf("(%.3f)", group_results[[grp]]$se)
})
cell_text <- mapply(function(val, se) {
  paste0(val, "\n", se)
}, table_values, table_ses, SIMPLIFY = TRUE)

results_df <- as.data.frame(t(cell_text))
colnames(results_df) <- group_names

results_df <- results_df |> 
  rename("-5 to -1" = "-5 to -1 (years)") |> 
  mutate(years = "ATT on GDP (Log)") 

results_df <- results_df |> 
  select(years, everything())
```


### Tabulation

```{r, echo=TRUE, eval=FALSE}
table_latex <- results_df |>
  kable(format = "latex",
        booktabs = TRUE,
        escape = FALSE,
        caption = "Semiparametric Estimates of the Effect 
        of Democratizations on GDP per Capita (Log)",
        label = "tab:table_5_ipw",
        digits = 3) |>
  add_header_above(c("Inverse propensity score reweighting" = ncol(results_df))) |>
  kable_styling(latex_options = c("hold_position", "scale_down"))

writeLines(table_latex, con = "output/table_5_ipw.tex")
```


\input{output/table_5_ipw.tex}

## Table.6 (Shoya Abe)

### Preprocessing

```{r}
data_t6 <- data  |> 
  group_by(country_name) |>
  arrange(year) |>
  mutate(
    lag1 = dplyr::lag(y, 1),
    lag2 = dplyr::lag(y, 2),
    lag3 = dplyr::lag(y, 3),
    lag4 = dplyr::lag(y, 4),
    lag5 = dplyr::lag(y, 5),
    lag6 = dplyr::lag(y, 6),
    lag7 = dplyr::lag(y, 7),
    lag8 = dplyr::lag(y, 8)
  ) |>
  ungroup() |>
  pdata.frame(index = c("country_name", "year"))
```

### Estimation

```{r}
model_iv_1 <- plm(
  y ~ dem + plm::lag(y, 1:4) |
    plm::lag(demreg, 1) + plm::lag(y, 1:4),
  data = data_t6,
  effect = "twoways"
)
model_iv_2 <- plm(
  y ~ dem + plm::lag(y, 1:4) |
    plm::lag(demreg, 1:4) + plm::lag(y, 1:4),
  data = data_t6,
  effect = "twoways"
)
model_iv_3 <- plm(
  y ~ dem + plm::lag(y, 1:4) + sov1 + sov2 + sov3 + sov4 |
    plm::lag(demreg, 1:4) + plm::lag(y, 1:4) +
    sov1 + sov2 + sov3 + sov4,
  data = data_t6,
  effect = "twoways"
)
model_iv_4 <- plm(
  y ~ dem + plm::lag(y, 1:4) +
    rtrend2 + rtrend3 + rtrend4 + rtrend5 + rtrend6 + rtrend7 |
    plm::lag(demreg, 1:4) + plm::lag(y, 1:4) +
    rtrend2 + rtrend3 + rtrend4 + rtrend5 + rtrend6 + rtrend7,
  data = data_t6,
  effect = "twoways",
  model = "within"
)

beta_hat_1 <- coef(model_iv_1)["dem"]
gamma_hat_1 <- coef(model_iv_1)[2:5]
long_run_effect_1 <- beta_hat_1 / (1 - sum(gamma_hat_1))

beta_hat_2 <- coef(model_iv_2)["dem"]
gamma_hat_2 <- coef(model_iv_2)[2:5]
long_run_effect_2 <- beta_hat_2 / (1 - sum(gamma_hat_2))

beta_hat_3 <- coef(model_iv_3)["dem"]
gamma_hat_3 <- coef(model_iv_3)[2:5]
long_run_effect_3 <- beta_hat_3 / (1 - sum(gamma_hat_3))

beta_hat_4 <- coef(model_iv_4)["dem"]
gamma_hat_4 <- coef(model_iv_4)[2:5]
long_run_effect_4 <- beta_hat_4 / (1 - sum(gamma_hat_4))

lre <- round(
  c(long_run_effect_1, long_run_effect_2,
    long_run_effect_3, long_run_effect_4),
  3
)

sre <- c()

dem_shortrun <- coef(model_iv_1)["dem"]
lag1 <- coef(model_iv_1)[2]
lag2 <- coef(model_iv_1)[3]
lag3 <- coef(model_iv_1)[4]
lag4 <- coef(model_iv_1)[5]
effect1 <- dem_shortrun
effect2 <- effect1 * lag1 + dem_shortrun
effect3 <- effect2 * lag1 + effect1 * lag2 + dem_shortrun
effect4 <- effect3 * lag1 + effect2 * lag2 +
  effect1 * lag3 + dem_shortrun
effects <- c(effect1, effect2, effect3, effect4)
for (i in 5:30) {
  eff <- effects[i - 1] * lag1 +
    effects[i - 2] * lag2 +
    effects[i - 3] * lag3 +
    effects[i - 4] * lag4 + dem_shortrun
  effects <- c(effects, eff)
}
sre <- c(sre, effects[25])

dem_shortrun <- coef(model_iv_2)["dem"]
lag1 <- coef(model_iv_2)[2]
lag2 <- coef(model_iv_2)[3]
lag3 <- coef(model_iv_2)[4]
lag4 <- coef(model_iv_2)[5]
effect1 <- dem_shortrun
effect2 <- effect1 * lag1 + dem_shortrun
effect3 <- effect2 * lag1 + effect1 * lag2 + dem_shortrun
effect4 <- effect3 * lag1 + effect2 * lag2 +
  effect1 * lag3 + dem_shortrun
effects <- c(effect1, effect2, effect3, effect4)
for (i in 5:30) {
  eff <- effects[i - 1] * lag1 +
    effects[i - 2] * lag2 +
    effects[i - 3] * lag3 +
    effects[i - 4] * lag4 + dem_shortrun
  effects <- c(effects, eff)
}
sre <- c(sre, effects[25])

dem_shortrun <- coef(model_iv_3)["dem"]
lag1 <- coef(model_iv_3)[2]
lag2 <- coef(model_iv_3)[3]
lag3 <- coef(model_iv_3)[4]
lag4 <- coef(model_iv_3)[5]
effect1 <- dem_shortrun
effect2 <- effect1 * lag1 + dem_shortrun
effect3 <- effect2 * lag1 + effect1 * lag2 + dem_shortrun
effect4 <- effect3 * lag1 + effect2 * lag2 +
  effect1 * lag3 + dem_shortrun
effects <- c(effect1, effect2, effect3, effect4)
for (i in 5:30) {
  eff <- effects[i - 1] * lag1 +
    effects[i - 2] * lag2 +
    effects[i - 3] * lag3 +
    effects[i - 4] * lag4 + dem_shortrun
  effects <- c(effects, eff)
}
sre <- c(sre, effects[25])

dem_shortrun <- coef(model_iv_4)["dem"]
lag1 <- coef(model_iv_4)[2]
lag2 <- coef(model_iv_4)[3]
lag3 <- coef(model_iv_4)[4]
lag4 <- coef(model_iv_4)[5]
effect1 <- dem_shortrun
effect2 <- effect1 * lag1 + dem_shortrun
effect3 <- effect2 * lag1 + effect1 * lag2 + dem_shortrun
effect4 <- effect3 * lag1 + effect2 * lag2 +
  effect1 * lag3 + dem_shortrun
effects <- c(effect1, effect2, effect3, effect4)
for (i in 5:30) {
  eff <- effects[i - 1] * lag1 +
    effects[i - 2] * lag2 +
    effects[i - 3] * lag3 +
    effects[i - 4] * lag4 + dem_shortrun
  effects <- c(effects, eff)
}
sre <- c(sre, effects[25])

sre <- round(sre, 3)

pers1 <- sum(coef(model_iv_1)[2:5])
pers2 <- sum(coef(model_iv_2)[2:5])
pers3 <- sum(coef(model_iv_3)[2:5])
pers4 <- sum(coef(model_iv_4)[2:5])
pers <- round(c(pers1, pers2, pers3, pers4), 3)
```

### Tabulation

```{r}
override.coef.1 <- coef(model_iv_1)["dem", drop = FALSE]
override.coef.2 <- coef(model_iv_2)["dem", drop = FALSE]
override.coef.3 <- coef(model_iv_3)["dem", drop = FALSE]
override.coef.4 <- coef(model_iv_4)["dem", drop = FALSE]
override.se.1 <- sqrt(diag(vcov(model_iv_1)))["dem"]
override.se.2 <- sqrt(diag(vcov(model_iv_2)))["dem"]
override.se.3 <- sqrt(diag(vcov(model_iv_3)))["dem"]
override.se.4 <- sqrt(diag(vcov(model_iv_4)))["dem"]
models <- list(model_iv_1, model_iv_2, model_iv_3, model_iv_4)

texreg(
  models,
  override.coef = list(
    override.coef.1,
    override.coef.2,
    override.coef.3,
    override.coef.4
  ),
  override.se = list(
    override.se.1,
    override.se.2,
    override.se.3,
    override.se.4
  ),
  custom.model.names = c(
    "1 Lag", "4 Lags",
    "Soviet Dummies",
    "Regional Trends"
  ),
  custom.coef.map = list(dem = "Democracy"),
  custom.gof.rows = list(
    "Persistence" = pers,
    "Long run effect" = lre,
    "Effect after 25 years" = sre
  ),
  file = "output/table_6_iv.tex",
  caption = "Effect of Democracy on (Log) GDP per Capita",
  include.rsquared = FALSE,
  include.adjrs = FALSE,
  include.fstat = FALSE
)
```

\input{output/table_6_iv.tex}

# Extention

## Confidence Interval by the Bootstrap Method (Shoya Abe)

In Figure 1 of the original paper, confidence intervals are not presented. We employ the bootstrap method to derive the confidence interval for the estimated ATT. This allows us to visualize the uncertainty associated with the estimated ATT.

### Bootstrap Method

We explain the bootstrap method used in our analysis. The bootstrap method is a computational simulation technique that allows us to estimate the distribution of a statistic in a finite sample. The procedure is conducted as follows:
\begin{enumerate}
    \item Randomly draw \( n \) observations with replacement from the original sample to generate \( n \) bootstrap samples.
    \item Estimate the ATT for each bootstrap sample.
    \item Compute the standard error of the ATT estimates obtained from the bootstrap samples.
    \item Use this standard error to estimate the confidence interval.
\end{enumerate}
Here, we derive the confidence interval using two different methods. The first method assumes that the distribution of the estimated ATT follows a normal distribution and estimates the confidence interval using the 2.5\% and 97.5\% percentiles. This corresponds to the light blue-shaded interval in Figure 3. The second method estimates the confidence interval using the 2.5\% and 97.5\% percentiles of the bootstrap distribution. This corresponds to the pink-shaded interval in Figure 3.

### Estimation

We estimate the confidence interval by executing the following code. The number of bootstrap replications is 200.

```{r, echo=TRUE, eval=FALSE}
compute_atets <- function(data_boot) {
  original_data <- data_f1
  data_f1 <<- data_boot
  out <- numeric(length(relative_times))
  for (i in seq_along(relative_times)) {
    t_val <- relative_times[i]
    if (t_val < 0) {
      col_name <- paste0("gdpDiff_m", abs(t_val))
    } else {
      col_name <- if (t_val == 0) "gdpDiff_0" else paste0("gdpDiff_p", t_val)
    }
    out[i] <- estimateATT(col_name)
  }
  data_f1 <<- original_data
  out
}

B <- 200
set.seed(123)
boot_mat <- matrix(NA, nrow = B, ncol = length(relative_times))
unique_ids <- unique(data_f1$id)

for (b in seq_len(B)) {
  sampled_ids <- sample(unique_ids, size = length(unique_ids), replace = TRUE)
  bs_data <- lapply(sampled_ids, function(x) {
    data_f1[data_f1$id == x, ]
  }) |> bind_rows()
  boot_mat[b, ] <- compute_atets(bs_data)
}

boot_se <- apply(boot_mat, 2, sd, na.rm = TRUE)
ci_lower_normal <- atets - 1.96 * boot_se
ci_upper_normal <- atets + 1.96 * boot_se

ci_lower_perc <- apply(boot_mat, 2, quantile, probs = 0.025, na.rm = TRUE)
ci_upper_perc <- apply(boot_mat, 2, quantile, probs = 0.975, na.rm = TRUE)

results_with_ci <- data.frame(
  RelativeTime = relative_times,
  ATT = atets,
  ciL_normal = ci_lower_normal,
  ciU_normal = ci_upper_normal,
  ciL_perc = ci_lower_perc,
  ciU_perc = ci_upper_perc
)
```

### Plot

```{r, echo=TRUE, eval=FALSE}
figure_1_withCI <- ggplot(results_with_ci, aes(x = RelativeTime, y = ATT)) +
  geom_line(color = "black") +
  geom_ribbon(aes(ymin = ciL_perc, ymax = ciU_perc), fill = "pink", alpha = 0.3) +
  geom_ribbon(aes(ymin = ciL_normal, ymax = ciU_normal), fill = "skyblue", alpha = 0.3) +
  scale_x_continuous(breaks = seq(-15, 30, 5)) +
  labs(
    x = "Years around Democratization",
    y = "Change in GDP per capita (log points)"
  ) +
  theme_bw()

ggsave("output/figure_1_withCI.pdf", 
       figure_1_withCI, 
       width = 14, 
       height = 8, 
       units = "cm")
```

![The Long-Term Impact of Democratization on Economic Growth (with the confidence interval)](output/figure_1_withCI.pdf)

Figure 1 appears to strongly support the claim that "Democracy does cause growth". However, when we look at Figure 2, which includes confidence intervals, the picture changes completely. While we do not deny that democratization has a positive effect on economic growth, it becomes clear that the long-term effects of democratization on economic growth are highly uncertain. Perhaps the authors chose not to display the confidence intervals, even if unintentionally, in a way that emphasized the claim that "Democracy does cause growth."

# References
::: {#refs}
:::

\newpage

# Appendix

## List of Variables (Shoya Abe)

```{r}
var_labels <- sapply(data, function(x) attr(x, "label"))
list_var <- tibble(
  variable = names(var_labels),
  label = var_labels
)

kable(
  list_var,
  format = "latex",
  booktabs = TRUE,
  longtable = TRUE,
  caption = "List of Variables"
) |>
  kable_styling(latex_options = "repeat_header")
```

## Arellano Bond Estimation for Table.2 (Shoya Abe)

```{r, echo=TRUE, eval=FALSE}
data_t2 <- data |>
  select(1:30) |>
  group_by(country_name) |>
  arrange(year) |>
  mutate(
    lag1 = dplyr::lag(y, 1),
    lag2 = dplyr::lag(y, 2),
    lag3 = dplyr::lag(y, 3),
    lag4 = dplyr::lag(y, 4),
    lag5 = dplyr::lag(y, 5),
    lag6 = dplyr::lag(y, 6),
    lag7 = dplyr::lag(y, 7),
    lag8 = dplyr::lag(y, 8)
  ) |>
  ungroup()

data_m1 <- data_t2 |>
  drop_na(y, dem, lag1) |>
  pdata.frame(index = c("country_name", "year"))
data_m2 <- data_t2 |>
  drop_na(y, dem, lag1, lag2) |>
  pdata.frame(index = c("country_name", "year"))
data_m3 <- data_t2 |>
  drop_na(y, dem, lag1, lag2, lag3, lag4) |>
  pdata.frame(index = c("country_name", "year"))
data_m4 <- data_t2 |>
  drop_na(
    y, dem, lag1, lag2, lag3, lag4,
    lag5, lag6, lag7, lag8
  ) |>
  pdata.frame(index = c("country_name", "year"))

maxlag <- 49

model_1_gmm <- pgmm(
  y ~ dem + lag(y, 1) |
    lag(y, 2:maxlag) + lag(dem, 1:maxlag),
  data = data_m1,
  effect = "twoways",
  model = "twosteps",
  transformation = "d"
)

model_2_gmm <- pgmm(
  y ~ dem + lag(y, 1) + lag(y, 2) |
    lag(y, 2:maxlag) + lag(dem, 1:maxlag),
  data = data_m2,
  effect = "twoways",
  model = "twosteps",
  transformation = "d"
)

model_3_gmm <- pgmm(
  y ~ dem + lag(y, 1) + lag(y, 2) +
    lag(y, 3) + lag(y, 4) |
    lag(y, 2:maxlag) + lag(dem, 1:maxlag),
  data = data_m3,
  effect = "twoways",
  model = "twosteps",
  transformation = "d"
)

model_4_gmm <- pgmm(
  y ~ dem + lag(y, 1) + lag(y, 2) +
    lag(y, 3) + lag(y, 4) +
    lag(y, 5) + lag(y, 6) +
    lag(y, 7) + lag(y, 8) |
    lag(y, 2:maxlag) + lag(dem, 1:maxlag),
  data = data_m4,
  effect = "twoways",
  model = "twosteps",
  transformation = "d"
)

compute_dynamic_effect <- function(dem_coef, lag_coefs, n_periods) {
  effects <- numeric(n_periods)
  effects[1] <- dem_coef
  k <- length(lag_coefs)
  if (n_periods > 1) {
    for (i in 2:n_periods) {
      eff <- dem_coef
      for (j in 1:min(i - 1, k)) {
        eff <- eff + effects[i - j] * lag_coefs[j]
      }
      effects[i] <- eff
    }
  }
  effects[n_periods]
}

coef_1 <- coef(model_1_gmm)
dem_coef_1 <- coef_1["dem"]
lag1_1 <- coef_1["lag(y, 1)"]
lre1 <- dem_coef_1 / (1 - lag1_1)
pers1 <- lag1_1
eff_25_1 <- compute_dynamic_effect(
  dem_coef_1, c(lag1_1), 25
)

coef_2 <- coef(model_2_gmm)
dem_coef_2 <- coef_2["dem"]
lag1_2 <- coef_2["lag(y, 1)"]
lag2_2 <- coef_2["lag(y, 2)"]
lre2 <- dem_coef_2 / (1 - (lag1_2 + lag2_2))
pers2 <- lag1_2 + lag2_2
eff_25_2 <- compute_dynamic_effect(
  dem_coef_2, c(lag1_2, lag2_2), 25
)

coef_3 <- coef(model_3_gmm)
dem_coef_3 <- coef_3["dem"]
lag1_3 <- coef_3["lag(y, 1)"]
lag2_3 <- coef_3["lag(y, 2)"]
lag3_3 <- coef_3["lag(y, 3)"]
lag4_3 <- coef_3["lag(y, 4)"]
lre3 <- dem_coef_3 / (1 - (lag1_3 +
  lag2_3 + lag3_3 + lag4_3))
pers3 <- lag1_3 + lag2_3 + lag3_3 + lag4_3
eff_25_3 <- compute_dynamic_effect(
  dem_coef_3, c(lag1_3, lag2_3, lag3_3, lag4_3), 25
)

coef_4 <- coef(model_4_gmm)
dem_coef_4 <- coef_4["dem"]
lag1_4 <- coef_4["lag(y, 1)"]
lag2_4 <- coef_4["lag(y, 2)"]
lag3_4 <- coef_4["lag(y, 3)"]
lag4_4 <- coef_4["lag(y, 4)"]
lag5_4 <- coef_4["lag(y, 5)"]
lag6_4 <- coef_4["lag(y, 6)"]
lag7_4 <- coef_4["lag(y, 7)"]
lag8_4 <- coef_4["lag(y, 8)"]
lre4 <- dem_coef_4 / (1 - (lag1_4 +
  lag2_4 + lag3_4 + lag4_4 + lag5_4 +
  lag6_4 + lag7_4 + lag8_4))
pers4 <- lag1_4 + lag2_4 + lag3_4 +
  lag4_4 + lag5_4 + lag6_4 + lag7_4 + lag8_4
eff_25_4 <- compute_dynamic_effect(
  dem_coef_4,
  c(
    lag1_4, lag2_4, lag3_4, lag4_4,
    lag5_4, lag6_4, lag7_4, lag8_4
  ),
  25
)

lre <- round(c(lre1, lre2, lre3, lre4), 3)
pers <- round(c(pers1, pers2, pers3, pers4), 3)
eff_25 <- round(
  c(eff_25_1, eff_25_2, eff_25_3, eff_25_4),
  3
)

se1 <- sqrt(diag(vcov(model_1_gmm)))
se2 <- sqrt(diag(vcov(model_2_gmm)))
se3 <- sqrt(diag(vcov(model_3_gmm)))
se4 <- sqrt(diag(vcov(model_4_gmm)))

override.coef.1 <- c(
  coef_1["dem"],
  coef_1["lag(y, 1)"],
  rep(NA, 7)
)
override.se.1 <- c(
  se1["dem"],
  se1["lag(y, 1)"],
  rep(NA, 7)
)
override.coef.2 <- c(
  coef_2["dem"],
  coef_2["lag(y, 1)"],
  coef_2["lag(y, 2)"],
  rep(NA, 6)
)
override.se.2 <- c(
  se2["dem"],
  se2["lag(y, 1)"],
  se2["lag(y, 2)"],
  rep(NA, 6)
)
override.coef.3 <- c(
  coef_3["dem"],
  coef_3["lag(y, 1)"],
  coef_3["lag(y, 2)"],
  coef_3["lag(y, 3)"],
  coef_3["lag(y, 4)"],
  rep(NA, 4)
)
override.se.3 <- c(
  se3["dem"],
  se3["lag(y, 1)"],
  se3["lag(y, 2)"],
  se3["lag(y, 3)"],
  se3["lag(y, 4)"],
  rep(NA, 4)
)
override.coef.4 <- c(
  coef_4["dem"],
  coef_4["lag(y, 1)"],
  coef_4["lag(y, 2)"],
  coef_4["lag(y, 3)"],
  coef_4["lag(y, 4)"],
  coef_4["lag(y, 5)"],
  coef_4["lag(y, 6)"],
  coef_4["lag(y, 7)"],
  coef_4["lag(y, 8)"]
)
override.se.4 <- c(
  se4["dem"],
  se4["lag(y, 1)"],
  se4["lag(y, 2)"],
  se4["lag(y, 3)"],
  se4["lag(y, 4)"],
  se4["lag(y, 5)"],
  se4["lag(y, 6)"],
  se4["lag(y, 7)"],
  se4["lag(y, 8)"]
)

models <- list(model_1_gmm, model_2_gmm, model_3_gmm, model_4_gmm)

texreg(
  models,
  override.coef = list(
    override.coef.1,
    override.coef.2,
    override.coef.3,
    override.coef.4
  ),
  override.se = list(
    override.se.1,
    override.se.2,
    override.se.3,
    override.se.4
  ),
  custom.model.names = c("(1)", "(2)", "(3)", "(4)"),
  custom.coef.names = c(
    "Democracy", "Lag 1", "Lag 2",
    "Lag 3", "Lag 4", "Lag 5",
    "Lag 6", "Lag 7", "Lag 8"
  ),
  custom.gof.rows = list(
    "Persistence" = pers,
    "Long run effect" = lre,
    "Effect after 25 years" = eff_25
  ),
  file = "output/table_2_GMM.tex",
  caption = "Effect of Democracy on (Log) GDP per Capita: Arellano–Bond GMM Estimation"
)
```

\input{output/table_2_GMM.tex}





